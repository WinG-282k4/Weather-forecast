{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f9378e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97ecb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_day_data(driver, year, month, day):\n",
    "    \"\"\"Crawl weather data for a specific day using existing driver\"\"\"\n",
    "    print(f\"Crawling {day}/{month}/{year}...\")\n",
    "    \n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        select_element = wait.until(EC.presence_of_element_located((By.ID, \"wt-his-select\")))\n",
    "        select = Select(select_element)\n",
    "        \n",
    "        day_value = f\"{year}{month:02d}{day:02d}\"\n",
    "        \n",
    "        options_values = [opt.get_attribute(\"value\") for opt in select.options]\n",
    "        if day_value not in options_values:\n",
    "            print(f\"Ngày {day}/{month}/{year} không có trong danh sách lựa chọn.\")\n",
    "            return []\n",
    "        \n",
    "        select.select_by_value(day_value)\n",
    "        \n",
    "        wait.until(EC.presence_of_element_located((By.ID, \"wt-his\")))\n",
    "        time.sleep(1)\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        \n",
    "        data = []\n",
    "        table = soup.find(\"table\", {\"id\": \"wt-his\"})\n",
    "        if not table:\n",
    "            print(f\"Không có bảng dữ liệu cho ngày {day}/{month}/{year}\")\n",
    "            return data\n",
    "        \n",
    "        date_str = f\"{year}-{month:02d}-{day:02d}\"\n",
    "        rows = table.find_all(\"tr\")\n",
    "        for row in rows[2:]:  # skip header rows\n",
    "            cols = row.find_all([\"th\", \"td\"])\n",
    "            if len(cols) >= 9:\n",
    "                try:\n",
    "                    hour = cols[0].text.strip().split('\\n')[0].strip()\n",
    "                    temp = float(cols[2].text.strip().replace(\"°C\", \"\").strip()) if \"°C\" in cols[2].text else None\n",
    "                    \n",
    "                    # ✅ Thêm cột weather\n",
    "                    weather = cols[3].text.strip() if cols[3].text.strip() else None\n",
    "                    \n",
    "                    wind_text = cols[4].text.strip()\n",
    "                    if \"No wind\" in wind_text:\n",
    "                        wind_speed = 0.0\n",
    "                    else:\n",
    "                        try:\n",
    "                            wind_speed = float(wind_text.replace(\"km/h\", \"\").strip())\n",
    "                        except:\n",
    "                            wind_speed = None\n",
    "                    \n",
    "                    try:\n",
    "                        wind_direction_span = cols[5].find(\"span\")\n",
    "                        if wind_direction_span and \"title\" in wind_direction_span.attrs:\n",
    "                            wind_direction = wind_direction_span[\"title\"]\n",
    "                            wind_angle = float(wind_direction.split(\"°\")[0].replace(\"Wind blowing from \", \"\").strip())\n",
    "                        else:\n",
    "                            wind_angle = None\n",
    "                    except:\n",
    "                        wind_angle = None\n",
    "                    \n",
    "                    humidity = float(cols[6].text.strip().replace(\"%\", \"\").strip()) if \"%\" in cols[6].text else None\n",
    "                    pressure = float(cols[7].text.strip().replace(\"mbar\", \"\").strip()) if \"mbar\" in cols[7].text else None\n",
    "                    \n",
    "                    vis_text = cols[8].text.strip()\n",
    "                    visibility = float(vis_text.replace(\"km\", \"\").strip()) if \"km\" in vis_text else None\n",
    "                    \n",
    "                    data.append({\n",
    "                        \"date\": date_str,\n",
    "                        \"hour\": hour,\n",
    "                        \"temperature\": temp,\n",
    "                        \"weather\": weather,  # ✅ thêm vào dict\n",
    "                        \"wind_speed\": wind_speed,\n",
    "                        \"wind_angle\": wind_angle,\n",
    "                        \"humidity\": humidity,\n",
    "                        \"pressure\": pressure,\n",
    "                        \"visibility\": visibility\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Lỗi dữ liệu {day}/{month}/{year} giờ {hour if 'hour' in locals() else 'unknown'}: {e}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi xử lý ngày {day}/{month}/{year}: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_days_in_month(year, month):\n",
    "    if month == 12:\n",
    "        next_month = datetime(year + 1, 1, 1)\n",
    "    else:\n",
    "        next_month = datetime(year, month + 1, 1)\n",
    "    last_day = next_month - timedelta(days=1)\n",
    "    return last_day.day\n",
    "\n",
    "def crawl_month(year, month):\n",
    "    print(f\"Processing month {month}/{year}\")\n",
    "    days_in_month = get_days_in_month(year, month)\n",
    "    \n",
    "    if year == datetime.now().year and month == datetime.now().month:\n",
    "        days_in_month = min(days_in_month, datetime.now().day)\n",
    "    \n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://www.timeanddate.com/weather/vietnam/da-nang/historic?month={month}&year={year}\"\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.ID, \"wt-his-select\")))\n",
    "        \n",
    "        all_data = []\n",
    "        for day in range(1, days_in_month + 1):\n",
    "            day_data = crawl_day_data(driver, year, month, day)\n",
    "            all_data.extend(day_data)\n",
    "            time.sleep(1)\n",
    "        return all_data\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing month 1/2020\n",
      "Processing month 2/2020\n",
      "Processing month 3/2020\n",
      "Processing month 4/2020\n",
      "Crawling 1/1/2020...\n",
      "Crawling 2/1/2020...\n",
      "Crawling 3/1/2020...\n",
      "Crawling 1/2/2020...\n",
      "Crawling 1/3/2020...\n",
      "Crawling 4/1/2020...\n",
      "Crawling 1/4/2020...\n",
      "Crawling 2/2/2020...\n",
      "Crawling 2/3/2020...\n",
      "Crawling 5/1/2020...\n",
      "Crawling 2/4/2020...\n",
      "Crawling 3/2/2020...\n",
      "Crawling 3/3/2020...\n",
      "Crawling 6/1/2020...\n",
      "Crawling 3/4/2020...\n",
      "Crawling 4/2/2020...\n",
      "Crawling 4/3/2020...\n",
      "Crawling 7/1/2020...\n",
      "Crawling 4/4/2020...\n",
      "Crawling 5/2/2020...\n",
      "Crawling 5/3/2020...\n",
      "Crawling 8/1/2020...\n",
      "Crawling 5/4/2020...\n",
      "Crawling 6/2/2020...\n",
      "Crawling 6/3/2020...\n",
      "Crawling 9/1/2020...\n",
      "Crawling 6/4/2020...\n",
      "Crawling 7/2/2020...\n",
      "Crawling 7/3/2020...\n",
      "Crawling 10/1/2020...\n",
      "Crawling 7/4/2020...\n",
      "Crawling 8/2/2020...\n",
      "Crawling 8/3/2020...\n",
      "Crawling 11/1/2020...\n",
      "Crawling 8/4/2020...\n",
      "Crawling 9/2/2020...\n",
      "Crawling 9/3/2020...\n",
      "Crawling 12/1/2020...\n",
      "Crawling 9/4/2020...\n",
      "Crawling 10/2/2020...\n",
      "Crawling 10/3/2020...\n",
      "Crawling 13/1/2020...\n",
      "Crawling 10/4/2020...\n",
      "Crawling 11/2/2020...\n",
      "Crawling 11/3/2020...\n",
      "Crawling 14/1/2020...\n",
      "Crawling 11/4/2020...\n",
      "Crawling 12/2/2020...\n",
      "Crawling 12/3/2020...\n",
      "Crawling 15/1/2020...\n",
      "Crawling 12/4/2020...\n",
      "Crawling 13/2/2020...\n",
      "Crawling 13/3/2020...\n",
      "Crawling 16/1/2020...\n",
      "Crawling 13/4/2020...\n",
      "Crawling 14/2/2020...\n",
      "Crawling 14/3/2020...\n",
      "Crawling 17/1/2020...\n",
      "Crawling 14/4/2020...\n",
      "Crawling 15/2/2020...\n",
      "Crawling 15/3/2020...\n",
      "Crawling 18/1/2020...\n",
      "Crawling 15/4/2020...\n",
      "Crawling 16/2/2020...\n",
      "Crawling 16/3/2020...\n",
      "Crawling 19/1/2020...\n",
      "Crawling 16/4/2020...\n",
      "Crawling 17/2/2020...\n",
      "Crawling 17/3/2020...\n",
      "Crawling 20/1/2020...\n",
      "Crawling 17/4/2020...\n",
      "Crawling 18/2/2020...\n",
      "Crawling 18/3/2020...\n",
      "Crawling 21/1/2020...\n",
      "Crawling 18/4/2020...\n",
      "Crawling 19/2/2020...\n",
      "Crawling 19/3/2020...\n",
      "Crawling 22/1/2020...\n",
      "Crawling 19/4/2020...\n",
      "Crawling 20/2/2020...\n",
      "Crawling 20/3/2020...\n",
      "Crawling 23/1/2020...\n",
      "Crawling 20/4/2020...\n",
      "Crawling 21/2/2020...\n",
      "Crawling 21/3/2020...\n",
      "Crawling 24/1/2020...\n",
      "Crawling 21/4/2020...\n",
      "Crawling 22/2/2020...\n",
      "Crawling 22/3/2020...\n",
      "Crawling 25/1/2020...\n",
      "Crawling 22/4/2020...\n",
      "Crawling 23/2/2020...\n",
      "Crawling 23/3/2020...\n",
      "Crawling 26/1/2020...\n",
      "Crawling 23/4/2020...\n",
      "Crawling 24/2/2020...\n",
      "Crawling 24/3/2020...\n",
      "Crawling 27/1/2020...\n",
      "Crawling 24/4/2020...\n",
      "Crawling 25/2/2020...\n",
      "Crawling 25/3/2020...\n",
      "Crawling 28/1/2020...\n",
      "Crawling 25/4/2020...\n",
      "Crawling 26/2/2020...\n",
      "Crawling 26/3/2020...\n",
      "Crawling 29/1/2020...\n",
      "Crawling 26/4/2020...\n",
      "Crawling 27/2/2020...\n",
      "Crawling 27/3/2020...\n",
      "Crawling 30/1/2020...\n",
      "Crawling 27/4/2020...\n",
      "Crawling 28/2/2020...\n",
      "Crawling 28/3/2020...\n",
      "Crawling 31/1/2020...\n",
      "Crawling 28/4/2020...\n",
      "Crawling 29/2/2020...\n",
      "Crawling 29/3/2020...\n",
      "Crawling 29/4/2020...\n",
      "Crawling 30/3/2020...Processing month 5/2020\n",
      "\n",
      "Crawling 30/4/2020...\n",
      "Processing month 6/2020\n",
      "Crawling 31/3/2020...\n",
      "Processing month 7/2020\n",
      "Processing month 8/2020\n",
      "Crawling 1/6/2020...\n",
      "Crawling 1/5/2020...\n",
      "Crawling 2/6/2020...\n",
      "Crawling 2/5/2020...\n",
      "Crawling 1/7/2020...\n",
      "Crawling 3/6/2020...\n",
      "Crawling 3/5/2020...\n",
      "Crawling 2/7/2020...\n",
      "Crawling 4/6/2020...\n",
      "Crawling 4/5/2020...\n",
      "Crawling 1/8/2020...\n",
      "Crawling 3/7/2020...\n",
      "Crawling 5/6/2020...\n",
      "Crawling 5/5/2020...\n",
      "Crawling 2/8/2020...\n",
      "Crawling 4/7/2020...\n",
      "Crawling 6/6/2020...\n",
      "Crawling 6/5/2020...\n",
      "Crawling 3/8/2020...\n",
      "Crawling 5/7/2020...\n",
      "Crawling 7/6/2020...\n",
      "Crawling 7/5/2020...\n",
      "Crawling 4/8/2020...\n",
      "Crawling 6/7/2020...\n",
      "Crawling 8/6/2020...\n",
      "Crawling 8/5/2020...\n",
      "Crawling 5/8/2020...\n",
      "Crawling 7/7/2020...\n",
      "Crawling 9/6/2020...\n",
      "Crawling 9/5/2020...\n",
      "Crawling 6/8/2020...\n",
      "Crawling 8/7/2020...\n",
      "Crawling 10/6/2020...\n",
      "Crawling 10/5/2020...\n",
      "Crawling 7/8/2020...\n",
      "Crawling 9/7/2020...\n",
      "Crawling 11/6/2020...\n",
      "Crawling 11/5/2020...\n",
      "Crawling 8/8/2020...\n",
      "Crawling 10/7/2020...\n",
      "Crawling 12/6/2020...\n",
      "Crawling 12/5/2020...\n",
      "Crawling 9/8/2020...\n",
      "Crawling 11/7/2020...\n",
      "Crawling 13/6/2020...\n",
      "Crawling 13/5/2020...\n",
      "Crawling 10/8/2020...\n",
      "Crawling 12/7/2020...\n",
      "Crawling 14/6/2020...\n",
      "Crawling 14/5/2020...\n",
      "Crawling 11/8/2020...\n",
      "Crawling 13/7/2020...\n",
      "Crawling 15/6/2020...\n",
      "Crawling 15/5/2020...\n",
      "Crawling 12/8/2020...\n",
      "Crawling 14/7/2020...\n",
      "Crawling 16/6/2020...\n",
      "Crawling 16/5/2020...\n",
      "Crawling 13/8/2020...\n",
      "Crawling 15/7/2020...\n",
      "Crawling 17/6/2020...\n",
      "Crawling 17/5/2020...\n",
      "Crawling 14/8/2020...\n",
      "Crawling 16/7/2020...\n",
      "Crawling 18/6/2020...\n",
      "Crawling 18/5/2020...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start_year = 2020\n",
    "    end_year = 2025\n",
    "    \n",
    "    all_data = []\n",
    "    tasks = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        max_month = 12\n",
    "        if year == datetime.now().year:\n",
    "            max_month = datetime.now().month\n",
    "        \n",
    "        for month in range(1, max_month + 1):\n",
    "            tasks.append((year, month))\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = executor.map(lambda args: crawl_month(*args), tasks)\n",
    "        for res in results:\n",
    "            all_data.extend(res)\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    print(\"Đã thu thập xong dữ liệu.\")\n",
    "    print(f\"Tổng số bản ghi: {len(df)}\")\n",
    "    print(df.head())\n",
    "    \n",
    "    df.to_csv(\"raw_data.csv\", index=False, na_rep=\"N/A\")\n",
    "    print(\"Đã lưu file CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0ff0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253428a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_day_data(driver, year, month, day):\n",
    "    \"\"\"Crawl weather data for a specific day using existing driver\"\"\"\n",
    "    print(f\"Crawling {day}/{month}/{year}...\")\n",
    "    \n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        select_element = wait.until(EC.presence_of_element_located((By.ID, \"wt-his-select\")))\n",
    "        select = Select(select_element)\n",
    "        \n",
    "        day_value = f\"{year}{month:02d}{day:02d}\"\n",
    "        \n",
    "        options_values = [opt.get_attribute(\"value\") for opt in select.options]\n",
    "        if day_value not in options_values:\n",
    "            print(f\"Ngày {day}/{month}/{year} không có trong danh sách lựa chọn.\")\n",
    "            return []\n",
    "        \n",
    "        select.select_by_value(day_value)\n",
    "        \n",
    "        wait.until(EC.presence_of_element_located((By.ID, \"wt-his\")))\n",
    "        time.sleep(1)\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        \n",
    "        data = []\n",
    "        table = soup.find(\"table\", {\"id\": \"wt-his\"})\n",
    "        if not table:\n",
    "            print(f\"Không có bảng dữ liệu cho ngày {day}/{month}/{year}\")\n",
    "            return data\n",
    "        \n",
    "        date_str = f\"{year}-{month:02d}-{day:02d}\"\n",
    "        rows = table.find_all(\"tr\")\n",
    "        for row in rows[2:]:  # skip header rows\n",
    "            cols = row.find_all([\"th\", \"td\"])\n",
    "            if len(cols) >= 9:\n",
    "                try:\n",
    "                    hour = cols[0].text.strip().split('\\n')[0].strip()\n",
    "                    temp = float(cols[2].text.strip().replace(\"°C\", \"\").strip()) if \"°C\" in cols[2].text else None\n",
    "                    \n",
    "                    # ✅ Thêm cột weather\n",
    "                    weather = cols[3].text.strip() if cols[3].text.strip() else None\n",
    "                    \n",
    "                    wind_text = cols[4].text.strip()\n",
    "                    if \"No wind\" in wind_text:\n",
    "                        wind_speed = 0.0\n",
    "                    else:\n",
    "                        try:\n",
    "                            wind_speed = float(wind_text.replace(\"km/h\", \"\").strip())\n",
    "                        except:\n",
    "                            wind_speed = None\n",
    "                    \n",
    "                    try:\n",
    "                        wind_direction_span = cols[5].find(\"span\")\n",
    "                        if wind_direction_span and \"title\" in wind_direction_span.attrs:\n",
    "                            wind_direction = wind_direction_span[\"title\"]\n",
    "                            wind_angle = float(wind_direction.split(\"°\")[0].replace(\"Wind blowing from \", \"\").strip())\n",
    "                        else:\n",
    "                            wind_angle = None\n",
    "                    except:\n",
    "                        wind_angle = None\n",
    "                    \n",
    "                    humidity = float(cols[6].text.strip().replace(\"%\", \"\").strip()) if \"%\" in cols[6].text else None\n",
    "                    pressure = float(cols[7].text.strip().replace(\"mbar\", \"\").strip()) if \"mbar\" in cols[7].text else None\n",
    "                    \n",
    "                    vis_text = cols[8].text.strip()\n",
    "                    visibility = float(vis_text.replace(\"km\", \"\").strip()) if \"km\" in vis_text else None\n",
    "                    \n",
    "                    data.append({\n",
    "                        \"date\": date_str,\n",
    "                        \"hour\": hour,\n",
    "                        \"temperature\": temp,\n",
    "                        \"weather\": weather,  # ✅ thêm vào dict\n",
    "                        \"wind_speed\": wind_speed,\n",
    "                        \"wind_angle\": wind_angle,\n",
    "                        \"humidity\": humidity,\n",
    "                        \"pressure\": pressure,\n",
    "                        \"visibility\": visibility\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Lỗi dữ liệu {day}/{month}/{year} giờ {hour if 'hour' in locals() else 'unknown'}: {e}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi xử lý ngày {day}/{month}/{year}: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_days_in_month(year, month):\n",
    "    if month == 12:\n",
    "        next_month = datetime(year + 1, 1, 1)\n",
    "    else:\n",
    "        next_month = datetime(year, month + 1, 1)\n",
    "    last_day = next_month - timedelta(days=1)\n",
    "    return last_day.day\n",
    "\n",
    "def crawl_month(year, month):\n",
    "    print(f\"Processing month {month}/{year}\")\n",
    "    days_in_month = get_days_in_month(year, month)\n",
    "    \n",
    "    if year == datetime.now().year and month == datetime.now().month:\n",
    "        days_in_month = min(days_in_month, datetime.now().day)\n",
    "    \n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://www.timeanddate.com/weather/vietnam/da-nang/historic?month={month}&year={year}\"\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.ID, \"wt-his-select\")))\n",
    "        \n",
    "        all_data = []\n",
    "        for day in range(1, days_in_month + 1):\n",
    "            day_data = crawl_day_data(driver, year, month, day)\n",
    "            all_data.extend(day_data)\n",
    "            time.sleep(1)\n",
    "        return all_data\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb9042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing month 1/2020\n",
      "Processing month 2/2020\n",
      "Processing month 3/2020\n",
      "Processing month 4/2020\n",
      "Crawling 1/1/2020...\n",
      "Crawling 2/1/2020...\n",
      "Crawling 3/1/2020...\n",
      "Crawling 1/2/2020...\n",
      "Crawling 1/3/2020...\n",
      "Crawling 4/1/2020...\n",
      "Crawling 1/4/2020...\n",
      "Crawling 2/2/2020...\n",
      "Crawling 2/3/2020...\n",
      "Crawling 5/1/2020...\n",
      "Crawling 2/4/2020...\n",
      "Crawling 3/2/2020...\n",
      "Crawling 3/3/2020...\n",
      "Crawling 6/1/2020...\n",
      "Crawling 3/4/2020...\n",
      "Crawling 4/2/2020...\n",
      "Crawling 4/3/2020...\n",
      "Crawling 7/1/2020...\n",
      "Crawling 4/4/2020...\n",
      "Crawling 5/2/2020...\n",
      "Crawling 5/3/2020...\n",
      "Crawling 8/1/2020...\n",
      "Crawling 5/4/2020...\n",
      "Crawling 6/2/2020...\n",
      "Crawling 6/3/2020...\n",
      "Crawling 9/1/2020...\n",
      "Crawling 6/4/2020...\n",
      "Crawling 7/2/2020...\n",
      "Crawling 7/3/2020...\n",
      "Crawling 10/1/2020...\n",
      "Crawling 7/4/2020...\n",
      "Crawling 8/2/2020...\n",
      "Crawling 8/3/2020...\n",
      "Crawling 11/1/2020...\n",
      "Crawling 8/4/2020...\n",
      "Crawling 9/2/2020...\n",
      "Crawling 9/3/2020...\n",
      "Crawling 12/1/2020...\n",
      "Crawling 9/4/2020...\n",
      "Crawling 10/2/2020...\n",
      "Crawling 10/3/2020...\n",
      "Crawling 13/1/2020...\n",
      "Crawling 10/4/2020...\n",
      "Crawling 11/2/2020...\n",
      "Crawling 11/3/2020...\n",
      "Crawling 14/1/2020...\n",
      "Crawling 11/4/2020...\n",
      "Crawling 12/2/2020...\n",
      "Crawling 12/3/2020...\n",
      "Crawling 15/1/2020...\n",
      "Crawling 12/4/2020...\n",
      "Crawling 13/2/2020...\n",
      "Crawling 13/3/2020...\n",
      "Crawling 16/1/2020...\n",
      "Crawling 13/4/2020...\n",
      "Crawling 14/2/2020...\n",
      "Crawling 14/3/2020...\n",
      "Crawling 17/1/2020...\n",
      "Crawling 14/4/2020...\n",
      "Crawling 15/2/2020...\n",
      "Crawling 15/3/2020...\n",
      "Crawling 18/1/2020...\n",
      "Crawling 15/4/2020...\n",
      "Crawling 16/2/2020...\n",
      "Crawling 16/3/2020...\n",
      "Crawling 19/1/2020...\n",
      "Crawling 16/4/2020...\n",
      "Crawling 17/2/2020...\n",
      "Crawling 17/3/2020...\n",
      "Crawling 20/1/2020...\n",
      "Crawling 17/4/2020...\n",
      "Crawling 18/2/2020...\n",
      "Crawling 18/3/2020...\n",
      "Crawling 21/1/2020...\n",
      "Crawling 18/4/2020...\n",
      "Crawling 19/2/2020...\n",
      "Crawling 19/3/2020...\n",
      "Crawling 22/1/2020...\n",
      "Crawling 19/4/2020...\n",
      "Crawling 20/2/2020...\n",
      "Crawling 20/3/2020...\n",
      "Crawling 23/1/2020...\n",
      "Crawling 20/4/2020...\n",
      "Crawling 21/2/2020...\n",
      "Crawling 21/3/2020...\n",
      "Crawling 24/1/2020...\n",
      "Crawling 21/4/2020...\n",
      "Crawling 22/2/2020...\n",
      "Crawling 22/3/2020...\n",
      "Crawling 25/1/2020...\n",
      "Crawling 22/4/2020...\n",
      "Crawling 23/2/2020...\n",
      "Crawling 23/3/2020...\n",
      "Crawling 26/1/2020...\n",
      "Crawling 23/4/2020...\n",
      "Crawling 24/2/2020...\n",
      "Crawling 24/3/2020...\n",
      "Crawling 27/1/2020...\n",
      "Crawling 24/4/2020...\n",
      "Crawling 25/2/2020...\n",
      "Crawling 25/3/2020...\n",
      "Crawling 28/1/2020...\n",
      "Crawling 25/4/2020...\n",
      "Crawling 26/2/2020...\n",
      "Crawling 26/3/2020...\n",
      "Crawling 29/1/2020...\n",
      "Crawling 26/4/2020...\n",
      "Crawling 27/2/2020...\n",
      "Crawling 27/3/2020...\n",
      "Crawling 30/1/2020...\n",
      "Crawling 27/4/2020...\n",
      "Crawling 28/2/2020...\n",
      "Crawling 28/3/2020...\n",
      "Crawling 31/1/2020...\n",
      "Crawling 28/4/2020...\n",
      "Crawling 29/2/2020...\n",
      "Crawling 29/3/2020...\n",
      "Crawling 29/4/2020...\n",
      "Crawling 30/3/2020...Processing month 5/2020\n",
      "\n",
      "Crawling 30/4/2020...\n",
      "Processing month 6/2020\n",
      "Crawling 31/3/2020...\n",
      "Processing month 7/2020\n",
      "Processing month 8/2020\n",
      "Crawling 1/6/2020...\n",
      "Crawling 1/5/2020...\n",
      "Crawling 2/6/2020...\n",
      "Crawling 2/5/2020...\n",
      "Crawling 1/7/2020...\n",
      "Crawling 3/6/2020...\n",
      "Crawling 3/5/2020...\n",
      "Crawling 2/7/2020...\n",
      "Crawling 4/6/2020...\n",
      "Crawling 4/5/2020...\n",
      "Crawling 1/8/2020...\n",
      "Crawling 3/7/2020...\n",
      "Crawling 5/6/2020...\n",
      "Crawling 5/5/2020...\n",
      "Crawling 2/8/2020...\n",
      "Crawling 4/7/2020...\n",
      "Crawling 6/6/2020...\n",
      "Crawling 6/5/2020...\n",
      "Crawling 3/8/2020...\n",
      "Crawling 5/7/2020...\n",
      "Crawling 7/6/2020...\n",
      "Crawling 7/5/2020...\n",
      "Crawling 4/8/2020...\n",
      "Crawling 6/7/2020...\n",
      "Crawling 8/6/2020...\n",
      "Crawling 8/5/2020...\n",
      "Crawling 5/8/2020...\n",
      "Crawling 7/7/2020...\n",
      "Crawling 9/6/2020...\n",
      "Crawling 9/5/2020...\n",
      "Crawling 6/8/2020...\n",
      "Crawling 8/7/2020...\n",
      "Crawling 10/6/2020...\n",
      "Crawling 10/5/2020...\n",
      "Crawling 7/8/2020...\n",
      "Crawling 9/7/2020...\n",
      "Crawling 11/6/2020...\n",
      "Crawling 11/5/2020...\n",
      "Crawling 8/8/2020...\n",
      "Crawling 10/7/2020...\n",
      "Crawling 12/6/2020...\n",
      "Crawling 12/5/2020...\n",
      "Crawling 9/8/2020...\n",
      "Crawling 11/7/2020...\n",
      "Crawling 13/6/2020...\n",
      "Crawling 13/5/2020...\n",
      "Crawling 10/8/2020...\n",
      "Crawling 12/7/2020...\n",
      "Crawling 14/6/2020...\n",
      "Crawling 14/5/2020...\n",
      "Crawling 11/8/2020...\n",
      "Crawling 13/7/2020...\n",
      "Crawling 15/6/2020...\n",
      "Crawling 15/5/2020...\n",
      "Crawling 12/8/2020...\n",
      "Crawling 14/7/2020...\n",
      "Crawling 16/6/2020...\n",
      "Crawling 16/5/2020...\n",
      "Crawling 13/8/2020...\n",
      "Crawling 15/7/2020...\n",
      "Crawling 17/6/2020...\n",
      "Crawling 17/5/2020...\n",
      "Crawling 14/8/2020...\n",
      "Crawling 16/7/2020...\n",
      "Crawling 18/6/2020...\n",
      "Crawling 18/5/2020...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start_year = 2020\n",
    "    end_year = 2025\n",
    "    \n",
    "    all_data = []\n",
    "    tasks = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        max_month = 12\n",
    "        if year == datetime.now().year:\n",
    "            max_month = datetime.now().month\n",
    "        \n",
    "        for month in range(1, max_month + 1):\n",
    "            tasks.append((year, month))\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = executor.map(lambda args: crawl_month(*args), tasks)\n",
    "        for res in results:\n",
    "            all_data.extend(res)\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    print(\"Đã thu thập xong dữ liệu.\")\n",
    "    print(f\"Tổng số bản ghi: {len(df)}\")\n",
    "    print(df.head())\n",
    "    \n",
    "    df.to_csv(\"raw_data.csv\", index=False, na_rep=\"N/A\")\n",
    "    print(\"Đã lưu file CSV.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
